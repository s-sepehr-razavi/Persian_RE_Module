{"data_dir": "./dataset/docred", "transformer_type": "roberta", "model_name_or_path": "roberta-large", "model_type": "ttmre", "train_file": "train_revised.json", "distant_file": "train_distant.json", "dev_file": "dev_revised.json", "test_file": "test_revised.json", "save_path": "out/train_revised_roberta_ttmre_docred_S-PU_isrank_1_m_1.0_e_1.0_seed_74", "load_path": "", "config_name": "", "tokenizer_name": "", "max_seq_length": "1024", "train_batch_size": "4", "test_batch_size": "4", "gradient_accumulation_steps": "1", "learning_rate": "3e-05", "adam_epsilon": "1e-06", "max_grad_norm": "1.0", "warmup_ratio": "0.06", "num_train_epochs": "30.0", "evaluation_steps": "-1", "seed": "74", "num_class": "97", "isrank": "1", "m_tag": "S-PU", "beta": "0.0", "gamma": "1.0", "m": "1.0", "e": "1.0", "pretrain_distant": "4", "num_layers": "4", "memory_size": "200", "n_gpu": "8", "device": "cuda:0"}